from pyspark.sql.functions import udf
from pyspark.sql.types import DoubleType

# Função auxiliar para calcular a derivada segundo as regras (passos 5, 6 e 7)
def calc_derivative(x, y, idx, side):
    n = len(x)
    # side pode ser 'left', 'right' ou 'interior'
    if side == 'left':  # primeiro ponto (x₀)
        if n > 2:
            cond = ((x[2] - x[1]) / (y[2] - y[1])) - ((x[1] - x[0]) / (y[1] - y[0]))
            if cond < 0:
                # Se a condição for satisfeita, usa a diferença simples
                fprime = (y[1] - y[0]) / (x[1] - x[0])
            else:
                # Caso contrário, utiliza a fórmula conforme passo (5)
                fprime_next = (y[2] - y[1]) / (x[2] - x[1])
                fprime = (3 * (y[1] - y[0]) / (2 * (x[1] - x[0]))) - (fprime_next / 2)
        else:
            fprime = (y[1] - y[0]) / (x[1] - x[0])
        return fprime

    elif side == 'right':  # último ponto (xₙ₋₁)
        if n > 2:
            cond = ((x[n-1] - x[n-2]) / (y[n-1] - y[n-2])) - ((x[n-2] - x[n-3]) / (y[n-2] - y[n-3]))
            if cond < 0:
                fprime = (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
            else:
                fprime_temp = (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
                fprime = (3 * (y[n-1] - y[n-2]) / (2 * (x[n-1] - x[n-2]))) - (fprime_temp / 2)
        else:
            fprime = (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
        return fprime

    else:  # ponto interior
        if idx + 1 < n - 1:
            cond = ((x[idx+2] - x[idx+1]) / (y[idx+2] - y[idx+1])) - ((x[idx+1] - x[idx]) / (y[idx+1] - y[idx]))
            if cond < 0:
                # Se a condição for satisfeita, usa a diferença centrada
                fprime = (y[idx+1] - y[idx-1]) / (x[idx+1] - x[idx-1])
            else:
                fprime_next = (y[idx+2] - y[idx+1]) / (x[idx+2] - x[idx+1])
                fprime = (3 * (y[idx+1] - y[idx]) / (2 * (x[idx+1] - x[idx]))) - (fprime_next / 2)
        else:
            # Se não há ponto à frente para comparar, usa a diferença simples
            fprime = (y[idx] - y[idx-1]) / (x[idx] - x[idx-1])
        return fprime

# Função que realiza a interpolação cúbica constrained unidimensional
def cubic_spline_interp(x, y, x_interp):
    n = len(x)
    if n < 2:
        return None
    # Ajusta fronteiras
    if x_interp <= x[0]:
        return y[0]
    if x_interp >= x[-1]:
        return y[-1]
    # Encontra o intervalo: índice i tal que x[i-1] <= x_interp <= x[i]
    i = 1
    while i < n and x_interp > x[i]:
        i += 1
    x0, x1 = x[i-1], x[i]
    y0, y1 = y[i-1], y[i]

    # Calcula as derivadas nos extremos do intervalo conforme as regras
    if i-1 == 0:
        m0 = calc_derivative(x, y, 0, 'left')
    else:
        m0 = calc_derivative(x, y, i-1, 'interior')

    if i == n-1:
        m1 = calc_derivative(x, y, n-1, 'right')
    else:
        m1 = calc_derivative(x, y, i, 'interior')

    # Cálculo das segundas derivadas (Equações 14 e 15)
    f2_x0 = (2 * (m1 - m0)) / (x1 - x0) + (6 * (y1 - y0)) / ((x1 - x0) ** 2)
    f2_x1 = (2 * (m1 + m0)) / (x1 - x0) + (6 * (y1 - y0)) / ((x1 - x0) ** 2)

    # Cálculo dos coeficientes (Equações 16 a 19)
    d = (f2_x1 - f2_x0) / (6 * (x1 - x0))                      # Eq (16)
    c = (x1 * f2_x0 - x0 * f2_x1) / (2 * (x1 - x0))              # Eq (17)
    b = ((y1 - y0) - c * (x1**2 - x0**2) - d * (x1**3 - x0**3)) / (x1 - x0)  # Eq (18)
    a = y0 - b * x0 - c * x0**2 - d * x0**3                      # Eq (19)

    # Avaliação da spline no ponto x_interp (Equação 20)
    return a + b * x_interp + c * (x_interp ** 2) + d * (x_interp ** 3)

# Função para interpolação bidimensional
def bidimensional_interp(deltas, tempos, vol_matrix, delta_interp, tempo_interp):
    # Primeiro: para cada linha (tempo) da matriz, interpola no eixo delta
    interp_por_tempo = []
    for vol_row in vol_matrix:
        interp_val = cubic_spline_interp(deltas, vol_row, delta_interp)
        interp_por_tempo.append(interp_val)
    # Segundo: interpola os valores obtidos no eixo tempo
    return cubic_spline_interp(tempos, interp_por_tempo, tempo_interp)

# UDF – a função recebe [deltas], [vol_matrix], [tempos], delta_interp e tempo_interp
@udf(DoubleType())
def bidim_interp_udf(deltas, vol_matrix, tempos, delta_interp, tempo_interp):
    try:
        return float(bidimensional_interp(deltas, tempos, vol_matrix, delta_interp, tempo_interp))
    except Exception as e:
        return None

# --- Criação de um Spark DataFrame de teste ---
# Exemplo de dados:
# - "deltas": vetor de deltas
# - "tempos": vetor de tempos (vencimentos)
# - "vol_matrix": matriz de volatilidades (cada linha corresponde a um tempo)
# - "delta_interp" e "tempo_interp": pontos a serem interpolados

data = [
    (
        [0.1, 0.2, 0.3, 0.4],     # deltas
        [1.0, 2.0, 3.0, 4.0],     # tempos
        [                         # vol_matrix: cada linha para um tempo
            [10, 20, 30, 40],     # tempo = 1.0
            [11, 21, 31, 41],     # tempo = 2.0
            [12, 22, 32, 42],     # tempo = 3.0
            [13, 23, 33, 43]      # tempo = 4.0
        ],
        0.25,   # delta_interp
        2.5     # tempo_interp
    )
]

columns = ["deltas", "tempos", "vol_matrix", "delta_interp", "tempo_interp"]

# Considerando que a sessão Spark já foi criada
df_teste = spark.createDataFrame(data, schema=columns)

# Aplica a UDF e cria a coluna "vol_interpolated"
df_teste = df_teste.withColumn("vol_interpolated", bidim_interp_udf("deltas", "vol_matrix", "tempos", "delta_interp", "tempo_interp"))

# Exibe o DataFrame de teste
df_teste.show(truncate=False)
