A seguir, apresento uma versão refatorada e otimizada do código. Nesta versão, mantemos todos os comentários e docstrings em português (como nas versões anteriores), mas foram aplicadas diversas otimizações para reduzir o consumo de memória e CPU, sem prejudicar o paralelismo do Spark. Algumas das principais alterações são:

Conversão dos arrays de entrada para objetos NumPy para aproveitar operações vetorizadas (como a deduplicação com np.unique) e evitar loops desnecessários em Python quando possível.

Uso de dicionário somente para o agrupamento dos dados medidos (que, normalmente, tem tamanho moderado em cada registro do grid de volatilidade) – essa operação foi mantida em loop, pois se os grids forem pequenos, o overhead é baixo; para grids muito grandes, outras estratégias (como uso de Pandas groupby) poderiam ser avaliadas, mas aqui assumimos que cada registro contém um grid moderado.

A UDTF (definida com pandas_udtf) processa cada linha de forma independente, retornando já um DataFrame com as linhas formatadas, sem a necessidade de “explode” posterior.

A formatação da chave foi ajustada para que o delta seja multiplicado por 10, arredondado e formatado com zfill(3) e o tempo (vencimento) seja convertido para inteiro com zfill(5).


Veja o código completo:


---

import numpy as np
import pandas as pd
from pyspark.sql.functions import pandas_udtf
from pyspark.sql.types import StructType, StructField, StringType, DoubleType
from typing import Iterator

# ====================================================================
# Função: calc_derivative
# ====================================================================
def calc_derivative(x, y, idx, side):
    """
    Calcula a primeira derivada f'(x) em um ponto usando regras de 
    diferenças finitas "constrained" segundo o lado do ponto (início, 
    interior ou final).

    Parâmetros:
      - x: lista ou array dos pontos do eixo independente.
      - y: lista ou array dos pontos do eixo dependente.
      - idx: índice do ponto onde a derivada será calculada.
      - side: string que indica se é o primeiro ('left'), último ('right')
              ou um ponto intermediário ('interior').

    Regras aplicadas:
      1. Para o primeiro ponto (side == 'left'):
         - Se houver pelo menos 3 pontos, calcula:
           cond = ((x[2]-x[1])/(y[2]-y[1])) - ((x[1]-x[0])/(y[1]-y[0])).
         - Se cond < 0, utiliza a diferença simples:
           f'(x₀) = (y₁ - y₀)/(x₁ - x₀).
         - Caso contrário, utiliza a fórmula:
           f'(x₀) = [3(y₁ - y₀)]⁄[2(x₁ - x₀)] – f'(x₂)/2.
      
      2. Para o último ponto (side == 'right'):
         - Utiliza os últimos três pontos e aplica lógica similar.
      
      3. Para pontos internos (side == 'interior'):
         - Se houver um ponto à frente (idx+2 < len(x)):
           - Calcula:
             cond = ((x[idx+2]-x[idx+1])/(y[idx+2]-y[idx+1])) - ((x[idx+1]-x[idx])/(y[idx+1]-y[idx])).
           - Se cond < 0, utiliza a diferença centrada:
             f'(xᵢ) = (y[i+1] - y[i-1])/(x[i+1] - x[i-1]).
           - Caso contrário, aplica:
             f'(xᵢ) = [3(y[i+1] - y[i])]/[2(x[i+1] - x[i])] – f'(x[i+2])/2.
         - Se não houver ponto à frente suficiente, usa a diferença simples.
    """
    n = len(x)
    if side == 'left':  # Primeiro ponto (x₀)
        if n > 2:
            cond = ((x[2] - x[1]) / (y[2] - y[1])) - ((x[1] - x[0]) / (y[1] - y[0]))
            if cond < 0:
                return (y[1] - y[0]) / (x[1] - x[0])
            else:
                fprime_next = (y[2] - y[1]) / (x[2] - x[1])
                return (3 * (y[1] - y[0]) / (2 * (x[1] - x[0]))) - (fprime_next / 2)
        else:
            return (y[1] - y[0]) / (x[1] - x[0])
    elif side == 'right':  # Último ponto
        if n > 2:
            cond = ((x[n-1] - x[n-2]) / (y[n-1] - y[n-2])) - ((x[n-2] - x[n-3]) / (y[n-2] - y[n-3]))
            if cond < 0:
                return (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
            else:
                fprime_temp = (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
                return (3 * (y[n-1] - y[n-2]) / (2 * (x[n-1] - x[n-2]))) - (fprime_temp / 2)
        else:
            return (y[n-1] - y[n-2]) / (x[n-1] - x[n-2])
    else:  # Ponto interior
        if idx + 1 < n - 1:
            cond = ((x[idx+2] - x[idx+1]) / (y[idx+2] - y[idx+1])) - ((x[idx+1] - x[idx]) / (y[idx+1] - y[idx]))
            if cond < 0:
                return (y[idx+1] - y[idx-1]) / (x[idx+1] - x[idx-1])
            else:
                fprime_next = (y[idx+2] - y[idx+1]) / (x[idx+2] - x[idx+1])
                return (3 * (y[idx+1] - y[idx]) / (2 * (x[idx+1] - x[idx]))) - (fprime_next / 2)
        else:
            return (y[idx] - y[idx-1]) / (x[idx] - x[idx-1])

# ====================================================================
# Função: cubic_spline_interp
# ====================================================================
def cubic_spline_interp(x, y, x_interp):
    """
    Realiza a interpolação cúbica "constrained" unidimensional usando as 
    Equações (14) a (20).

    Passos:
      1. Verificação de Fronteira:
         Se x_interp for menor ou igual ao primeiro ponto de x, retorna y[0].
         Se x_interp for maior ou igual ao último ponto, retorna y[-1].
      2. Localização do Intervalo:
         Encontra o índice i tal que x[i-1] ≤ x_interp ≤ x[i].
      3. Cálculo das Derivadas (f'):
         Utiliza a função calc_derivative para obter:
           - m₀ = f'(x[i-1]) (usando 'left' se for o primeiro ou 'interior').
           - m₁ = f'(x[i]) (usando 'right' se for o último ou 'interior').
      4. Cálculo das Segundas Derivadas (f″):
         Aplica as Equações:
           - f″(x[i-1]) = [2(m₁ - m₀)] / (x[i]-x[i-1]) + [6(y[i]-y[i-1])] / (x[i]-x[i-1])²  
             (Equação 14)
           - f″(x[i])   = [2(m₁ + m₀)] / (x[i]-x[i-1]) + [6(y[i]-y[i-1])] / (x[i]-x[i-1])²  
             (Equação 15)
      5. Cálculo dos Coeficientes da Spline:
         Calcula os coeficientes:
           - d = [f″(x[i]) - f″(x[i-1])] / [6(x[i]-x[i-1])]  (Equação 16)
           - c = [x[i]*f″(x[i-1]) - x[i-1]*f″(x[i])] / [2(x[i]-x[i-1])]  (Equação 17)
           - b = { (y[i]-y[i-1]) - c*(x[i]² - x[i-1]²) - d*(x[i]³ - x[i-1]³) } / (x[i]-x[i-1])  
             (Equação 18)
           - a = y[i-1] - b*x[i-1] - c*x[i-1]² - d*x[i-1]³  (Equação 19)
      6. Avaliação da Spline:
         Retorna:
           y(x_interp) = a + b*x_interp + c*x_interp² + d*x_interp³  (Equação 20)

    Caso haja apenas 2 pontos, utiliza interpolação linear.
    """
    n = len(x)
    if n == 2:
        if x_interp <= x[0]:
            return y[0]
        if x_interp >= x[1]:
            return y[1]
        return y[0] + (y[1]-y[0])*((x_interp-x[0])/(x[1]-x[0]))
    
    if x_interp <= x[0]:
        return y[0]
    if x_interp >= x[-1]:
        return y[-1]
    i = 1
    while i < n and x_interp > x[i]:
        i += 1
    x0, x1 = x[i-1], x[i]
    y0, y1 = y[i-1], y[i]
    m0 = calc_derivative(x, y, 0 if i-1==0 else i-1, 'left' if i-1==0 else 'interior')
    m1 = calc_derivative(x, y, n-1 if i==n-1 else i, 'right' if i==n-1 else 'interior')
    f2_x0 = (2*(m1-m0))/(x1-x0) + 6*(y1-y0)/((x1-x0)**2)
    f2_x1 = (2*(m1+m0))/(x1-x0) + 6*(y1-y0)/((x1-x0)**2)
    d = (f2_x1 - f2_x0) / (6*(x1-x0))
    c = (x1*f2_x0 - x0*f2_x1) / (2*(x1-x0))
    b = ((y1-y0) - c*(x1**2-x0**2) - d*(x1**3-x0**3)) / (x1-x0)
    a = y0 - b*x0 - c*(x0**2) - d*(x0**3)
    return a + b*x_interp + c*(x_interp**2) + d*(x_interp**3)

# ====================================================================
# Função: bidimensional_interp
# ====================================================================
def bidimensional_interp(deltas, tempos, vol_matrix, delta_interp, tempo_interp):
    """
    Realiza a interpolação bidimensional nos eixos delta e tempo.

    Passos:
      1. Para cada linha da matriz de volatilidades (cada tempo), interpola 
         no eixo delta utilizando cubic_spline_interp, com x = deltas, y = linha,
         e x_interp = delta_interp. Isso gera um vetor (um valor por tempo).
      2. Com esse vetor, interpola no eixo tempo (com x = tempos, y = vetor resultante,
         e x_interp = tempo_interp) para obter o valor final interpolado.
    """
    interp_por_tempo = [cubic_spline_interp(deltas, row, delta_interp) for row in vol_matrix]
    return cubic_spline_interp(tempos, interp_por_tempo, tempo_interp)

# ====================================================================
# Função Auxiliar: compute_multi_interp
# ====================================================================
def compute_multi_interp(volatilidades, tempos, deltas, query_deltas, query_tempos, ativo, data_referencia):
    """
    Processa uma única linha de entrada (com arrays de dados medidos e de consulta)
    e retorna uma lista de dicionários, cada um representando uma linha de saída com:
      - Data_referencia
      - chave (formada por ativo, delta e tempo de consulta)
      - Volatilidade_Interpolada

    Se houver mais de uma medição para o mesmo par (tempo, delta), os valores são somados.
    Otimizações:
      - Converte os inputs para arrays NumPy para operações vetorizadas onde possível.
      - Utiliza np.unique para deduplicação dos eixos.
    """
    # Converte para arrays NumPy para melhor performance
    vol_arr = np.asarray(volatilidades)
    tempos_arr = np.asarray(tempos)
    deltas_arr = np.asarray(deltas)
    
    # Agrupa as medições usando um dicionário
    data_dict = {}
    for i in range(len(vol_arr)):
        key = (tempos_arr[i], deltas_arr[i])
        data_dict[key] = data_dict.get(key, 0.0) + vol_arr[i]
    
    # Deduplica e ordena os eixos usando np.unique
    unique_tempos = np.unique(tempos_arr).tolist()
    unique_deltas = np.unique(deltas_arr).tolist()
    
    # Reconstrói a matriz 2D de volatilidades (vetorizado com list comprehension)
    vol_matrix = [[data_dict.get((t, d), 0.0) for d in unique_deltas] for t in unique_tempos]
    
    result_list = []
    # Itera somente sobre os pontos de consulta fornecidos
    for qt in query_tempos:
        for qd in query_deltas:
            interp_val = bidimensional_interp(unique_deltas, unique_tempos, vol_matrix, qd, qt)
            # Formata a chave:
            # - Delta: multiplicado por 10, arredondado, convertido para inteiro e com zfill(3)
            # - Tempo: convertido para inteiro e com zfill(5)
            delta_str = str(int(round(qd * 10))).zfill(3)
            tempo_str = str(int(qt)).zfill(5)
            chave = f"{ativo}_{delta_str}_{tempo_str}"
            result_list.append({
                "Data_referencia": data_referencia,
                "chave": chave,
                "Volatilidade_Interpolada": float(interp_val)
            })
    return result_list

# ====================================================================
# UDTF: multi_interp_udtf
# ====================================================================
# Define o schema de saída: já retorna um DataFrame com as colunas formatadas
output_schema = StructType([
    StructField("Data_referencia", StringType(), False),
    StructField("chave", StringType(), False),
    StructField("Volatilidade_Interpolada", DoubleType(), False)
])

@pandas_udtf(output_schema, functionType="iterator")
def multi_interp_udtf(volatilidades: pd.Series,
                      tempos: pd.Series,
                      deltas: pd.Series,
                      query_deltas: pd.Series,
                      query_tempos: pd.Series,
                      ativo: pd.Series,
                      data_referencia: pd.Series) -> Iterator[pd.DataFrame]:
    """
    UDTF que realiza a interpolação bidimensional da superfície de volatilidade.
    Para cada registro de entrada (com arrays de volatilidades, tempos, deltas,
    query_deltas e query_tempos, além do ativo e data_referencia), retorna um DataFrame
    com as colunas:
      - Data_referencia
      - chave (formato "ativo_{delta_formatado}_{tempo_formatado}")
      - Volatilidade_Interpolada

    Essa função é otimizada para processamento em lote, utilizando operações vetorizadas
    via NumPy e evitando loops desnecessários.
    """
    for i in range(len(volatilidades)):
        # Converte os valores para listas se já não forem
        vol = volatilidades.iloc[i]
        t = tempos.iloc[i]
        d = deltas.iloc[i]
        qd = query_deltas.iloc[i]
        qt = query_tempos.iloc[i]
        a_val = ativo.iloc[i]
        dr = data_referencia.iloc[i]
        result_list = compute_multi_interp(vol, t, d, qd, qt, a_val, dr)
        yield pd.DataFrame(result_list)

# ====================================================================
# Exemplo de Aplicação no DataFrame de Consulta
# ====================================================================
# Suponha que seu DataFrame de consulta contenha as colunas:
#   - Ativo
#   - Data_referencia
#   - volatilidades: array de floats (dados medidos)
#   - tempos: array de floats (dados medidos)
#   - deltas: array de floats (dados medidos)
#   - query_deltas: array de floats com os deltas de consulta (apenas os pontos desejados)
#   - query_tempos: array de floats com os tempos de consulta (apenas os pontos desejados)
data = [
    (
        "ABC",                     # Ativo
        "2025-03-31",              # Data_referencia
        [0.3, 0.5, 0.6, 0.1],        # volatilidades: ex. índice 0 -> (tempo=1.0, delta=0.05), 1 -> (tempo=2.0, delta=0.05), etc.
        [1.0, 2.0, 1.0, 2.0],        # tempos
        [0.05, 0.05, 0.1, 0.1],       # deltas
        [0.075, 0.085],             # query_deltas: somente os valores que quero consultar
        [1.5, 2.5]                  # query_tempos: somente os tempos que quero consultar
    )
]
columns = ["Ativo", "Data_referencia", "volatilidades", "tempos", "deltas", "query_deltas", "query_tempos"]
df = spark.createDataFrame(data, schema=columns)

# Aplica a UDTF para que o próprio retorno seja um DataFrame formatado (sem necessidade de explode)
final_df = df.selectExpr("multi_interp_udtf(volatilidades, tempos, deltas, query_deltas, query_tempos, Ativo, Data_referencia) as results") \
              .select("results.*")

final_df.show(truncate=False)


---

Resumo das Otimizações e Ajustes

1. Conversão para NumPy:
Na função auxiliar compute_multi_interp, os arrays de entrada são convertidos para NumPy para aproveitar operações vetorizadas e a função np.unique para deduplicação, reduzindo o overhead dos loops em Python.


2. Evitar Explode no Resultado:
A UDTF (definida com pandas_udtf) já retorna um DataFrame com as linhas resultantes, eliminando a necessidade de aplicar explode posteriormente.


3. Formatação da Chave:
A chave é formatada de acordo com as especificações:

O delta de consulta é multiplicado por 10, arredondado, convertido para inteiro e formatado com zfill(3).

O tempo (vencimento) é convertido para inteiro e formatado com zfill(5).



4. **Paralelismo



