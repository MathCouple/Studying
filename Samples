Aqui est√° o c√≥digo otimizado com list comprehensions onde poss√≠vel, mantendo a efici√™ncia:

from pyspark.sql import SparkSession
from pyspark.sql.functions import pandas_udf, col
from pyspark.sql.types import DoubleType
import pandas as pd
import numpy as np

# Criando uma Spark Session
spark = SparkSession.builder.appName("InterpolacaoCubica").getOrCreate()

# Criando um DataFrame de Exemplo
data = [
    (0.1, 30, 0.25),
    (0.1, 60, 0.28),
    (0.1, 90, 0.30),
    (0.1, 120, 0.32),
    (0.1, 150, 0.35),
    (0.2, 30, 0.20),
    (0.2, 60, 0.22),
    (0.2, 90, 0.24),
    (0.2, 120, 0.26),
    (0.2, 150, 0.29)
]
df = spark.createDataFrame(data, ["Delta", "Vencimento", "Vol"])

# Defini√ß√£o da UDF para interpola√ß√£o c√∫bica baseada nas equa√ß√µes (14) a (20)
@pandas_udf(DoubleType())
def interpolar_vol(vencimentos: pd.Series, vols: pd.Series, x_interp: float) -> pd.Series:
    """
    Aplica interpola√ß√£o c√∫bica nos pontos (Vencimento, Volatilidade Impl√≠cita)
    para estimar a volatilidade no ponto x_interp (tempo desejado).
    Segue as equa√ß√µes (14) a (20).
    """
    # Ordenando os valores
    sorted_indices = np.argsort(vencimentos)
    x, y = vencimentos.iloc[sorted_indices].values, vols.iloc[sorted_indices].values

    # Verifica se x_interp est√° dentro do intervalo conhecido
    if x_interp < x[0] or x_interp > x[-1]:
        return pd.Series(y[0] if x_interp < x[0] else y[-1])

    # Encontrar o intervalo correto (x_i ‚â§ x < x_{i+1})
    i = next(i for i in range(1, len(x)) if x[i-1] <= x_interp < x[i])

    # C√°lculo das derivadas iniciais
    f_prime_x1, f_prime_xn_1 = [(y[j] - y[j-1]) / (x[j] - x[j-1]) for j in [1, -1]]

    # C√°lculo das segundas derivadas (equa√ß√µes 14 e 15)
    f2_x_i_1, f2_x_i = [
        (2 * (f_prime_x1 - f_prime_xn_1) / (x[i] - x[i-1])) + (6 * (y[i] - y[i-1]) / (x[i] - x[i-1])**2),
        (2 * (f_prime_x1 + f_prime_xn_1) / (x[i] - x[i-1])) + (6 * (y[i] - y[i-1]) / (x[i] - x[i-1])**2)
    ]

    # Coeficientes c√∫bicos (equa√ß√µes 16 a 19)
    d_i, c_i = [(f2_x_i - f2_x_i_1) / (6 * (x[i] - x[i-1])),
                (x[i] * f2_x_i_1 - x[i-1] * f2_x_i) / (2 * (x[i] - x[i-1]))]

    b_i = ((y[i] - y[i-1]) - c_i * (x[i]**2 - x[i-1]**2) - d_i * (x[i]**3 - x[i-1]**3)) / (x[i] - x[i-1])
    a_i = y[i-1] - b_i * x[i-1] - c_i * x[i-1]**2 - d_i * x[i-1]**3

    # Aplica√ß√£o da equa√ß√£o (20) para interpola√ß√£o
    y_interp = a_i + b_i * x_interp + c_i * x_interp**2 + d_i * x_interp**3

    return pd.Series(y_interp)

# Supondo que queremos interpolar para um vencimento de 75 dias
x_interp = 75

# Aplicando a UDF no DataFrame agrupado por Delta
df_resultado = df.groupBy("Delta").agg(interpolar_vol(col("Vencimento"), col("Vol"), x_interp).alias("Vol_Interpolado"))

# Exibir o resultado
df_resultado.show()


---

Otimiza√ß√µes e Uso de List Comprehensions

‚úÖ Ordena√ß√£o e extra√ß√£o dos valores feita de forma eficiente.
‚úÖ Busca do intervalo correto feita com next(), evitando loops desnecess√°rios.
‚úÖ C√°lculo de derivadas e coeficientes c√∫bicos feito em list comprehension para reduzir linhas de c√≥digo.
‚úÖ Interpola√ß√£o final preservada para garantir m√°xima precis√£o.

Se precisar de mais melhorias, me avise! üöÄ

